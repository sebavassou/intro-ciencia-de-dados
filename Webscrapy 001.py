import time
import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException

def raspar_quotes_com_selenium():
    """
    Fun√ß√£o para fazer o web scraping do site quotes.toscrape.com usando Selenium,
    coletando todas as cita√ß√µes, autores e tags de todas as p√°ginas.

    Retorna:
        list: Uma lista de dicion√°rios, onde cada dicion√°rio representa uma cita√ß√£o.
    """
    # Configura op√ß√µes do Chrome para melhor performance
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # Executa sem interface gr√°fica (mais r√°pido)
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    
    # Configura e inicializa o navegador Chrome automaticamente
    try:
        driver = webdriver.Chrome(
            service=ChromeService(ChromeDriverManager().install()),
            options=chrome_options
        )
        print("Navegador Chrome inicializado com sucesso.")
    except WebDriverException as e:
        print(f"Erro ao inicializar o navegador: {e}")
        return []
    
    # URL inicial a ser acessada
    url = "http://quotes.toscrape.com/"
    
    try:
        driver.get(url)
        print(f"Acessando: {url}")
        
        # Aguarda a p√°gina carregar completamente
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'quote'))
        )
        
    except TimeoutException:
        print("Timeout: A p√°gina demorou muito para carregar.")
        driver.quit()
        return []
    except WebDriverException as e:
        print(f"Erro ao acessar a p√°gina: {e}")
        driver.quit()
        return []
    
    lista_de_quotes = []
    pagina_atual = 1

    while True:
        print(f"Raspando p√°gina {pagina_atual}: {driver.current_url}")
        
        try:
            # Aguarda os elementos de cita√ß√£o carregarem
            WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.CLASS_NAME, 'quote'))
            )
            quotes = driver.find_elements(By.CLASS_NAME, 'quote')
            
            if not quotes:
                print("Nenhuma cita√ß√£o encontrada na p√°gina atual.")
                break
                
        except TimeoutException:
            print("Timeout: Elementos de cita√ß√£o n√£o carregaram.")
            break

        # Itera sobre cada cont√™iner para extrair os dados
        for i, quote in enumerate(quotes, 1):
            try:
                # Extrai o texto da cita√ß√£o (elemento com a classe 'text')
                texto_element = quote.find_element(By.CLASS_NAME, 'text')
                texto = texto_element.text.strip('""').strip('""')
                
                # Extrai o nome do autor (elemento com a classe 'author')
                autor_element = quote.find_element(By.CLASS_NAME, 'author')
                autor = autor_element.text
                
                # Extrai as tags (elementos com a classe 'tag')
                tags_elementos = quote.find_elements(By.CLASS_NAME, 'tag')
                tags = [tag.text for tag in tags_elementos]

                # Adiciona os dados extra√≠dos como um dicion√°rio √† lista
                quote_data = {
                    'citacao': texto,
                    'autor': autor,
                    'tags': tags,
                    'pagina': pagina_atual
                }
                lista_de_quotes.append(quote_data)
                
            except NoSuchElementException as e:
                print(f"Erro ao extrair dados da cita√ß√£o {i} na p√°gina {pagina_atual}: {e}")
                continue
            except Exception as e:
                print(f"Erro inesperado na cita√ß√£o {i}: {e}")
                continue

        # Tenta encontrar e clicar no bot√£o "Next"
        try:
            # Aguarda o bot√£o "Next" estar presente e clic√°vel
            botao_next = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, 'li.next a'))
            )
            
            # Scroll para o bot√£o para garantir que est√° vis√≠vel
            driver.execute_script("arguments[0].scrollIntoView();", botao_next)
            time.sleep(0.5)
            
            botao_next.click()
            pagina_atual += 1
            
            # Pequena pausa para evitar sobrecarga do servidor
            time.sleep(1)
            
        except (NoSuchElementException, TimeoutException):
            # Se o bot√£o "Next" n√£o for encontrado, significa que estamos na √∫ltima p√°gina
            print(f"N√£o h√° mais p√°ginas para raspar. Total de p√°ginas processadas: {pagina_atual}")
            break
        except Exception as e:
            print(f"Erro ao navegar para a pr√≥xima p√°gina: {e}")
            break

    # Fecha o navegador ao final do processo
    print("Fechando o navegador...")
    driver.quit()
    
    return lista_de_quotes

def salvar_resultados(dados, formato='json'):
    """
    Salva os resultados em arquivo.
    
    Args:
        dados (list): Lista de cita√ß√µes coletadas
        formato (str): Formato do arquivo ('json' ou 'txt')
    """
    if not dados:
        print("Nenhum dado para salvar.")
        return
    
    if formato == 'json':
        with open('quotes_coletadas.json', 'w', encoding='utf-8') as f:
            json.dump(dados, f, ensure_ascii=False, indent=2)
        print("Dados salvos em 'quotes_coletadas.json'")
    
    elif formato == 'txt':
        with open('quotes_coletadas.txt', 'w', encoding='utf-8') as f:
            for i, quote in enumerate(dados, 1):
                f.write(f"Cita√ß√£o {i}:\n")
                f.write(f"Texto: {quote['citacao']}\n")
                f.write(f"Autor: {quote['autor']}\n")
                f.write(f"Tags: {', '.join(quote['tags'])}\n")
                f.write(f"P√°gina: {quote['pagina']}\n")
                f.write("-" * 50 + "\n\n")
        print("Dados salvos em 'quotes_coletadas.txt'")

# --- Execu√ß√£o Principal do Script ---
if __name__ == "__main__":
    print("=== Iniciando Web Scraping de Cita√ß√µes ===")
    
    try:
        resultado_final = raspar_quotes_com_selenium()
        
        if resultado_final:
            print(f"\n‚úÖ Web scraping conclu√≠do com sucesso!")
            print(f"üìä Total de {len(resultado_final)} cita√ß√µes coletadas.")
            
            # Estat√≠sticas adicionais
            autores_unicos = len(set(quote['autor'] for quote in resultado_final))
            paginas_processadas = max(quote['pagina'] for quote in resultado_final)
            
            print(f"üë• Autores √∫nicos: {autores_unicos}")
            print(f"üìÑ P√°ginas processadas: {paginas_processadas}")
            
            # Salva os resultados
            salvar_resultados(resultado_final, 'json')
            
            # Exemplo da primeira cita√ß√£o coletada
            print("\nüìù Exemplo da primeira cita√ß√£o coletada:")
            primeira_citacao = resultado_final[0]
            print(f"Texto: {primeira_citacao['citacao']}")
            print(f"Autor: {primeira_citacao['autor']}")
            print(f"Tags: {', '.join(primeira_citacao['tags'])}")
            
        else:
            print("‚ùå Nenhuma cita√ß√£o foi coletada. Verifique a conex√£o e tente novamente.")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Opera√ß√£o interrompida pelo usu√°rio.")
    except Exception as e:
        print(f"‚ùå Erro inesperado: {e}")